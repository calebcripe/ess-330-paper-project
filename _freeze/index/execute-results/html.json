{
  "hash": "1894a1f1acb631f1aa669030cd74afaf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Change in RMNP Average Snowpack with Annual Temperatures\nauthors:\n  - name: Caleb Cripe\n    affiliation: Colorado State University\n    roles: writing\n    corresponding: true\n  - name: Caitlin Rasbid\n    affiliation: Colorado State University\n    corresponding: false\nexecute: \n  echo: true\nbibliography: references.bib\ncsl: apa-6th-edition.csl\n---\n\n\n\n\n\n# Background\nThe issue of climate change has caused regime alterations across aspects of ecosystems, impacting ecosystems functioning and environmental services we utilize. Especially in the Western US, we rely on snowpack that accumulates during the winter to provide water for the drier months of the year, which means that decreased snowpack results in scarcity. Globally, snowpack substantially contributes to the livelihoods of over a billion people, who are both directly and indirectly dependent on meltwater resources. (@irannezhad2022snowpack) Decreased annual snowpack can have adverse impacts on fire conditions, making wildfires that start more dangerous and difficult to control. Reduced meltwater, soil moisture, and fuel moisture can greatly increase fire potential in forest systems, which we have already begun to see across the West. (@Gergel2017-vr) These factors increase the need for snowpack monitoring so urban populations are able to recognize when droughts are likely to occur and when fire risk is higher than average.\n\n# Data\nThe Snow Telemetry Network, or SNOTEL, collects snowpack and other water supply data across the US to support resource management initiatives. We will utilize SNOTEL data from the six sites located in Rocky Mountain National Park, pulling data on average snow water equivalent recorded, average snow depth, average snow temperature, (soil temperature observed?) and mean air temperature. The six sites we plan to analyze located within RMNP are Phantom Valley, Lake Irene, Willow Park, Bear Lake, Copeland Lake, and Wild Basin. Using the SNOTEL data, we can extract daily records for each of the variables at each of the six sites in RMNP over a 25 year period, allowing us to observe changes from the first quarter of the 21st century. \n\n# Exploring Our Data\nWe will filter the dataset to only include entries from the past 25 years at the six sites of interest in RMNP,  Phantom Valley, Lake Irene, Willow Park, Bear Lake, Copeland Lake, and Wild Basin. We will then filter out any variables that are not being assessed for relationship to annual snowpack, and create annual aggregate variables from average snow water equivalent recorded, average snow depth, average snow temperature, and mean air temperature to simplify the daily data into an annual average that will aid in assessing trends over many years. We will be doing this according to a snow year, with a year being from October-September.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(readr)\ninstall.packages(\"janitor\", repos = \"https://cloud.r-project.org\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nThe downloaded binary packages are in\n\t/var/folders/jn/hk4fnzlx679cs3m0_lnzh7hh0000gn/T//Rtmprq30eN/downloaded_packages\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(janitor)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'janitor'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nrmnp_snotel <- read_csv(\"rmnp_snotel(rmnp_snotel).csv\") %>%\n  janitor::clean_names()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 9133 Columns: 37\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Date\ndbl (36): Bear Lake (322) Snow Water Equivalent (in) Start of Day Values, Be...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyr)\n\nrmnp_clean <- rmnp_snotel %>%\n  drop_na()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ purrr     1.0.2\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(lubridate)\n\ndf <- rmnp_clean %>%\n  mutate(date = mdy(date),\n         year = year(date))\n\nswe_data <- df %>%\n  select(year, contains(\"snow_water_equivalent\")) %>%\n  pivot_longer(\n    cols = -year,\n    names_to = \"station\",\n    values_to = \"swe\"\n  )\n\nswe_data <- swe_data %>%\n  mutate(swe = as.numeric(swe))\n\nannual_swe <- swe_data %>%\n  filter(year < 2025) %>%\n  group_by(year) %>%\n  summarise(avg_swe = mean(swe, na.rm = TRUE))\n\nggplot(annual_swe, aes(x = year, y = avg_swe)) +\n  geom_line(color = \"blue\", linewidth = 1.2) +\n  geom_point(color = \"darkblue\") +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +\n  labs(title = \"Average SWE by Year (All Stations)\",\n       x = \"Year\", y = \"Average SWE (inches)\") +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntemp_data <- df %>%\n  select(year, contains(\"air_temperature_average\")) %>%\n  pivot_longer(\n    cols = -year,\n    names_to = \"station\",\n    values_to = \"temp\"\n  ) %>%\n  mutate(temp = as.numeric(temp))\n\nannual_temp <- temp_data %>%\n  filter(year < 2025) %>%\n  group_by(year) %>%\n  summarise(avg_temp = mean(temp, na.rm = TRUE))\n\nggplot(annual_temp, aes(x = year, y = avg_temp)) +\n  geom_line(color = \"tomato\", linewidth = 1.2) +\n  geom_point(color = \"firebrick\") +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n  labs(title = \"Average Air Temperature by Year (All Stations)\",\n       x = \"Year\", y = \"Avg Temp (°F)\") +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n\n\n## Preliminary Methods\nTo begin, we will conduct an exploratory data analysis using visual elements such as ggplots to represent trends in SWE over time and descriptive methods such as ANOVA to determine the differences in SWE by site. Visual exploration is important to understand if the nature of the relationship between variables is linear or if some transformation would better represent the relationship. After our visual exploration, we will perform any transformations necessary prior to model creation. If there appears to be a significant difference in SWE based on site, we may need to introduce site-specific variables such as elevation and latitude that will capture some individual site characteristics. \n\nWe can use other summary statistics such as cor() to assess any underlying correlations between variables that will influence model design and assess trends over time. Then we will use a simple linear regression with SWE as the predicted value and the five annual aggregate variables as predictors. This will allow us to get an idea of what variables are significant, if the relationship is positive or negative, and how well the model fits based on the R squared model. Likely the linear regression will not be a sufficient model, so we will use machine learning to create a workflow with additional model types, such as random forest or neural network. We could run into challenges in several ways, such as unexpected relationships between variables, missing data, or roadblocks associated with unfamiliarity with R and handling data. We expect to handle these challenges in different ways, but are preparing for them by reviewing past lecture material and re-familiarizing ourselves with commands that we need to use to achieve our goals.\n\nThese methods will provide us with helpful insights into our overall research question in several ways. First, visual exploration will show differences SWE over time and across sites, suggesting the impacts of climate change and which ecosystems seem to be most resistant to this change, if any. The ANOVA and summary statistics will serve a similar purpose. The linear and machine learning models we will build will be useful in understanding what impacts SWE to be able to predict future SWE levels based on environmental indicators.\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}